\documentclass[11pt]{article} % For LaTeX2e
\usepackage{nips12submit_e,times}
%\documentstyle[nips12submit_09,times,art10]{article} % For LaTeX 2.09

%\usepackage[usenames,dvipsnames]{color}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{textcomp}
\usepackage[scaled=0.8]{beramono}

\usepackage{caption}
\usepackage{subcaption}
\usepackage{wrapfig}
\usepackage{amsmath,amssymb}
\usepackage{array}
\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{graphicx}

\usepackage{cite}
\usepackage{url}
\usepackage[hyperfootnotes=false,citecolor=RedOrange,linkcolor=RoyalBlue,urlcolor=DarkOrchid,colorlinks]{hyperref}
\usepackage[all]{hypcap}

\newcommand{\todo}[1]{\noindent\texttt{\color[rgb]{0.5,0.1,0.1} TODO: #1}}

\newcommand{\sectref}[1]{\mbox{Section~\ref{#1}}}
\newcommand{\figref}[1]{\mbox{Figure~\ref{#1}}}
\newcommand{\tabref}[1]{\mbox{Table~\ref{#1}}}
\renewcommand{\sectref}[1]{\hyperref[#1]{\mbox{Section~\ref*{#1}}}}
\renewcommand{\figref}[1]{\hyperref[#1]{\mbox{Figure~\ref*{#1}}}}
\renewcommand{\tabref}[1]{\hyperref[#1]{\mbox{Table~\ref*{#1}}}}

\title{Active Learning of Function Contours using Gaussian Process Confidence Bounds\thanks{Final
report for the course \emph{Research in Computer Science} (Spring
Semester 2012), carried out under the supervision of \emph{Prof. Andreas Krause.}}}

\author{
Alkis Gkotovos\\
Department of Computer Science, ETH Zurich\\
\texttt{alkisg@student.ethz.ch}
}

\nipsfinalcopy % Uncomment for camera-ready version

\begin{document}

\maketitle

\begin{abstract}
We present a novel algorithm for actively identifying function
contours using the framework of Gaussian processes and utilizing the
inferred confidence bounds to guide the learning process. We also show how
the algorithm can be extended to identify $\epsilon$-optimal function contours.
Our method is evaluated and compared to the state of the art on synthetic and
real-world seismographic data.
\end{abstract}

\section{Introduction}


\section{Algorithm}
The problem of actively learning function contours can be described as follows.
Let ${f : \mathcal{D} \to \mathbb{R}}$ be the target function, where
$\mathcal{D}$ is a bounded subset of $\mathbb{R}^n$. We are interested in
finding the subset of $\mathcal{D}$ where this function takes values greater
than a specified threshold $h$, i.e. the set
$\mathcal{G} = \{x \in \mathcal{D} \mid f(x) > h\}$. To this end, we take
consecutive measurements $(x_i, f(x_i))$ of the function
and use them to determine $\mathcal{G}$. After the $i$-th step, the set of
all acquired measurements is
$\mathcal{M}_i = \{(x_1, f(x_1)),\ldots,(x_i, f(x_i))\}$.

Our basic premise is that the time required to obtain each measurement is
non-negligible and, therefore, taking a large number of random measurements
over the whole domain $\mathcal{D}$ is prohibitive. We rather aim at directing
the measurement process so that the chosen points $x_i$ are informative with
respect to the desired contours, which should result in accurately determining
the set $\mathcal{G}$ using a significantly smaller number of measurements
compared to random sampling.

In this setting, we have to decide on (1) a model that allows us to use the
measurements in order to obtain an approximation of $\mathcal{G}$, and (2) a
strategy to each time select the next point of measurement. The following
subsections deal with these two issues.

\subsection{Gaussian processes}
We chose to use Gaussian processes~\cite{gpbook} in modeling the target
function $f$, as they have been successfully used before in the context of
contour detection~\cite{bryan2005, bryan2008}. Gaussian process regression
offers a non-parametric framework for predicting the values of the function at
unobserved points, given a number of measurements. The characteristics of
the assumed underlying model are primarily specified by a kernel function
${K : \mathcal{D} \times \mathcal{D} \to \mathbb{R}}$, which determines the
covariance of any two points in $\mathcal{D}$.

In our active learning setting, $\mathcal{M}_i$ is used as a training set
for Gaussian process regression and the inferred values $g_i(x)$ of the
model are used to approximate the set $\mathcal{G}$ as
${\mathcal{G}_i = \{x \in \mathcal{D} \mid g_i(x) > h\}}$.

\subsection{Choosing the next point}

\subsection{Identifying $\epsilon$-optimal contours}

\section{Experiments}

\todo{Talk about Hausdorff here?}
\todo{Properly choosing kernel}

\subsection{Synthetic data}

\subsection{Seismographic data}

\bibliographystyle{plain}
\bibliography{report}

\end{document}
